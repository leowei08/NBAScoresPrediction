{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nba_api.stats.endpoints\n",
    "from nba_api.stats.endpoints import leaguegamefinder, playbyplayv2\n",
    "from nba_api.stats.static import teams\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import requests, sqlalchemy\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "\n",
    "# connect to postgres database\n",
    "engine = sqlalchemy.create_engine('postgresql://postgres:password@localhost:5432/NBA')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data from database\n",
    "work = pd.read_sql_query(\"select * from train\", con=engine)\n",
    "\n",
    "# playoffs dummy variable\n",
    "work['playoff'] = work['season_id'].str.extract(r'(\\d)\\d{4}').astype(int)\n",
    "work['playoff'] = work['playoff'].replace(2,0)\n",
    "work['playoff'] = work['playoff'].replace(4,1)\n",
    "work['season_id'] = work['season_id'].str.replace('^\\d','2')\n",
    "\n",
    "# Get season after 1995\n",
    "work = work[work['season_id'] >= '21996']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we dont need\n",
    "train = work.drop(columns=['team_id','team_abbreviation','game_date','matchup','min','days'])\n",
    "\n",
    "# compute difference in stats\n",
    "train['blk_diff'] = train['blk'] - train['blk_oppos']\n",
    "train['oreb_diff'] = train['oreb'] - train['oreb_oppos']\n",
    "train['reb_diff'] = train['reb'] - train['reb_oppos']\n",
    "train['ast_diff'] = train['ast'] - train['ast_oppos']\n",
    "train['stl_diff'] = train['stl'] - train['stl_oppos']\n",
    "train['tov_diff'] = train['tov'] - train['tov_oppos']\n",
    "train['pf_diff'] = train['pf'] - train['pf_oppos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the play-by-play data from database\n",
    "plays = pd.read_sql_query(\"select * from playbyplay\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the play-by-play data \n",
    "kmeans = KMeans(6, random_state=0).fit(plays.drop(columns=['game_id']))\n",
    "\n",
    "# new feature as cluster\n",
    "plays['clusters'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to training data\n",
    "train = train.merge(plays, left_on=['game_id'], right_on=['game_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy variables\n",
    "final = pd.concat([\n",
    "           pd.get_dummies(train['season_id']), \n",
    "           pd.get_dummies(train['wl'],drop_first=True), \n",
    "           pd.get_dummies(train['clusters'],prefix='cluster'),\n",
    "           train.drop(columns=['awayteam','season_id','wl','hometeam','game_id'])], axis=1)\n",
    "\n",
    "# Split into train and test data\n",
    "tr, te = train_test_split(final,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "rfr = RandomForestRegressor(max_depth=12, min_samples_split=64, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=12, min_samples_split=64, n_jobs=-1,\n",
       "                      random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "rfr.fit(tr.drop(columns=['2diff']), tr['2diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.373045180192985"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE on testing\n",
    "mean_absolute_error(te['2diff'],rfr.predict(te.drop(columns=['2diff'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.3139611855241"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE on training\n",
    "mean_absolute_error(tr['2diff'],rfr.predict(tr.drop(columns=['2diff'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team abbreviation conversion between our data and MSN\n",
    "team_dict = {'ATL': 'ATL',\n",
    " 'BKN': 'BKN',\n",
    " 'BOS': 'BOS',\n",
    " 'CHA': 'CHA',\n",
    " 'CHI': 'CHI',\n",
    " 'CLE': 'CLE',\n",
    " 'DAL': 'DAL',\n",
    " 'DEN': 'DEN',\n",
    " 'DET': 'DET',\n",
    " 'GS': 'GSW',\n",
    " 'HOU': 'HOU',\n",
    " 'IND': 'IND',\n",
    " 'LAC': 'LAC',\n",
    " 'LAL': 'LAL',\n",
    " 'MEM': 'MEM',\n",
    " 'MIA': 'MIA',\n",
    " 'MIL': 'MIL',\n",
    " 'MIN': 'MIN',\n",
    " 'NO': 'NOP',\n",
    " 'NY': 'NYK',\n",
    " 'OKC': 'OKC',\n",
    " 'ORL': 'ORL',\n",
    " 'PHI': 'PHI',\n",
    " 'PHO': 'PHX',\n",
    " 'POR': 'POR',\n",
    " 'SA': 'SAS',\n",
    " 'SAC': 'SAC',\n",
    " 'TOR': 'TOR',\n",
    " 'UTA': 'UTA',\n",
    " 'WAS': 'WAS'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get game schedule tomorrrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webscrape from MSN\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'}\n",
    "today = str(int(str(datetime.date.today()).replace('-','')))\n",
    "games_today = requests.get('https://www.msn.com/en-us/sports/nba/schedule', headers=headers)\n",
    "html_soup = BeautifulSoup(games_today.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to the number of days after the first game\n",
    "def convert_days(date):\n",
    "    d = pd.Timestamp(1983,10,28)\n",
    "    return (date - d).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictors from past data\n",
    "teamstoday = []\n",
    "page = html_soup.find_all('div',{'id':today})[0].find_all('td')\n",
    "for i in range (len(page)):\n",
    "    if i % 5 == 2:\n",
    "        teamstoday.append(page[i].text.split('\\n')[1].strip())\n",
    "        \n",
    "all_games = pd.read_sql_query(\"select * from raw\", con=engine)\n",
    "s = \"\" # email string\n",
    "for i in range (0, len(teamstoday), 2):\n",
    "    away = team_dict[teamstoday[i]]\n",
    "    home = team_dict[teamstoday[i+1]]\n",
    "    s += away + ',' + home + '\\n'\n",
    "    all_games['days'] = pd.to_datetime(all_games['game_date']).apply(convert_days)\n",
    "    all_games['hometeam'] = all_games['matchup'].str.extract(r'\\w* @ (\\w*)')\n",
    "    thiscomp1 = all_games[(all_games['team_abbreviation'] == away) & (all_games['hometeam'] == home)].reset_index(drop=True)\n",
    "    thiscomp2 = all_games[(all_games['team_abbreviation'] == home) & (all_games['hometeam'] == away)].reset_index(drop=True)\n",
    "    target = pd.concat([thiscomp1, thiscomp2]).sort_values('days').iloc[-1].drop(labels=['team_id','team_name','game_date','matchup','min'])\n",
    "    daysdiff = (pd.Timestamp.today() - pd.Timestamp(1983,10,28)).days - target['days']\n",
    "    \n",
    "    data = pd.Series([0]*final.shape[1], index = final.drop(columns=['2diff']).columns)\n",
    "    data['playoff'] = 0\n",
    "    data['22020'] = 1\n",
    "    if target['hometeam'] == home:\n",
    "        data['opposite'] = 0\n",
    "    else:\n",
    "        data['opposite'] = 1\n",
    "\n",
    "    if target['wl'] == 'W':\n",
    "        data['W'] = 1\n",
    "    else:\n",
    "        data['W'] = 0\n",
    "    \n",
    "    # compute the predictors\n",
    "    data['1diff'] = target['pts'] - target['pts_oppos']\n",
    "    data['daysdiff'] = daysdiff\n",
    "    data[28:64] = target[4:-2]\n",
    "    data[66:115] = team[(team['season'] == target['season_id']) & (team['team_abbreviation'] == target['team_abbreviation'])].drop(columns=['season_id','team_abbreviation','team_name','TEAM_ID','TEAM_NAME','GP','W','L','CFID','CFPARAMS','season']).iloc[0]\n",
    "    data[115:-7] = team[(team['season'] == target['season_id']) & (team['team_abbreviation'] == target['hometeam'])].drop(columns=['season_id','team_abbreviation','team_name','TEAM_ID','TEAM_NAME','GP','W','L','CFID','CFPARAMS','season']).iloc[0]\n",
    "    data['blk_diff'] = data['blk'] - data['blk_oppos']\n",
    "    data['oreb_diff'] = data['oreb'] - data['oreb_oppos']\n",
    "    data['reb_diff'] = data['reb'] - data['reb_oppos']\n",
    "    data['ast_diff'] = data['ast'] - data['ast_oppos']\n",
    "    data['stl_diff'] = data['stl'] - data['stl_oppos']\n",
    "    data['tov_diff'] = data['tov'] - data['tov_oppos']\n",
    "    data['pf_diff'] = data['pf'] - data['pf_oppos']\n",
    "    \n",
    "    # prediction\n",
    "    s += str(rfr.predict(data.values.reshape(1,-1))) + '\\n' # email string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over/Under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data training data from database\n",
    "work = pd.read_sql_query(\"select * from train_total\", con=engine)\n",
    "\n",
    "# playoffs indicator\n",
    "work['playoff'] = work['season_id'].str.extract(r'(\\d)\\d{4}').astype(int)\n",
    "work['playoff'] = work['playoff'].replace(2,0)\n",
    "work['playoff'] = work['playoff'].replace(4,1)\n",
    "\n",
    "# Get season after 1995\n",
    "work['season_id'] = work['season_id'].str.replace('^\\d','2')\n",
    "work = work[work['season_id'] >= '21996']\n",
    "\n",
    "# drop columns we dont need\n",
    "train = work.drop(columns=['team_id','team_abbreviation','game_date','matchup','min','days'])\n",
    "\n",
    "# compute stat difference\n",
    "train['blk_diff'] = train['blk'] - train['blk_oppos']\n",
    "train['oreb_diff'] = train['oreb'] - train['oreb_oppos']\n",
    "train['reb_diff'] = train['reb'] - train['reb_oppos']\n",
    "train['ast_diff'] = train['ast'] - train['ast_oppos']\n",
    "train['stl_diff'] = train['stl'] - train['stl_oppos']\n",
    "train['tov_diff'] = train['tov'] - train['tov_oppos']\n",
    "train['pf_diff'] = train['pf'] - train['pf_oppos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy variables\n",
    "final = pd.concat([\n",
    "           pd.get_dummies(train['season_id']), \n",
    "           pd.get_dummies(train['wl'],drop_first=True), \n",
    "           train.drop(columns=['awayteam','season_id','wl','hometeam','game_id'])], axis=1)\n",
    "\n",
    "# split into train and test dataset\n",
    "tr, te = train_test_split(final,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "rfr = RandomForestRegressor(max_depth=12, min_samples_split=64, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=12, min_samples_split=64, n_jobs=-1,\n",
       "                      random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "rfr.fit(tr.drop(columns=['2diff']), tr['2diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.881988864855604"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE for testing\n",
    "mean_absolute_error(te['2diff'],rfr.predict(te.drop(columns=['2diff'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.022569548413044"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE for training\n",
    "mean_absolute_error(tr['2diff'],rfr.predict(tr.drop(columns=['2diff'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get game schedule tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webscrape from MSN\n",
    "teamstoday = []\n",
    "page = html_soup.find_all('div',{'id':today})[0].find_all('td')\n",
    "for i in range (len(page)):\n",
    "    if i % 5 == 2:\n",
    "        teamstoday.append(page[i].text.split('\\n')[1].strip())\n",
    "\n",
    "# get raw data from database\n",
    "all_games = pd.read_sql_query(\"select * from raw\", con=engine)\n",
    "\n",
    "# get predictors from past data\n",
    "for i in range (0, len(teamstoday), 2):\n",
    "    away = team_dict[teamstoday[i]]\n",
    "    home = team_dict[teamstoday[i+1]]\n",
    "    s += away + ',' + home + '\\n' # email string\n",
    "    all_games['days'] = pd.to_datetime(all_games['game_date']).apply(convert_days)\n",
    "    all_games['hometeam'] = all_games['matchup'].str.extract(r'\\w* @ (\\w*)')\n",
    "    thiscomp1 = all_games[(all_games['team_abbreviation'] == away) & (all_games['hometeam'] == home)].reset_index(drop=True)\n",
    "    thiscomp2 = all_games[(all_games['team_abbreviation'] == home) & (all_games['hometeam'] == away)].reset_index(drop=True)\n",
    "    target = pd.concat([thiscomp1, thiscomp2]).sort_values('days').iloc[-1].drop(labels=['team_id','team_name','game_date','matchup','min'])\n",
    "    daysdiff = (pd.Timestamp.today() - pd.Timestamp(1983,10,28)).days - target['days']\n",
    "    \n",
    "    data = pd.Series([0]*final.shape[1], index = final.drop(columns=['2diff']).columns)\n",
    "    data['playoff'] = 0\n",
    "    data['22020'] = 1\n",
    "    if target['hometeam'] == home:\n",
    "        data['opposite'] = 0\n",
    "    else:\n",
    "        data['opposite'] = 1\n",
    "\n",
    "    if target['wl'] == 'W':\n",
    "        data['W'] = 1\n",
    "    else:\n",
    "        data['W'] = 0\n",
    "    \n",
    "    # compute the predictors\n",
    "    data['1diff'] = target['pts'] - target['pts_oppos']\n",
    "    data['daysdiff'] = daysdiff\n",
    "    data[28:64] = target[4:-2]\n",
    "    data[66:115] = team[(team['season'] == target['season_id']) & (team['team_abbreviation'] == target['team_abbreviation'])].drop(columns=['season_id','team_abbreviation','team_name','TEAM_ID','TEAM_NAME','GP','W','L','CFID','CFPARAMS','season']).iloc[0]\n",
    "    data[115:-7] = team[(team['season'] == target['season_id']) & (team['team_abbreviation'] == target['hometeam'])].drop(columns=['season_id','team_abbreviation','team_name','TEAM_ID','TEAM_NAME','GP','W','L','CFID','CFPARAMS','season']).iloc[0]\n",
    "    data['blk_diff'] = data['blk'] - data['blk_oppos']\n",
    "    data['oreb_diff'] = data['oreb'] - data['oreb_oppos']\n",
    "    data['reb_diff'] = data['reb'] - data['reb_oppos']\n",
    "    data['ast_diff'] = data['ast'] - data['ast_oppos']\n",
    "    data['stl_diff'] = data['stl'] - data['stl_oppos']\n",
    "    data['tov_diff'] = data['tov'] - data['tov_oppos']\n",
    "    data['pf_diff'] = data['pf'] - data['pf_oppos']\n",
    "    \n",
    "    # prediction\n",
    "    s += str(rfr.predict(data.values.reshape(1,-1))) + '\\n' # email string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib, ssl\n",
    "\n",
    "port = 465  # For SSL\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "sender_email = \"leowei08@gmail.com\"\n",
    "receiver_email1 = \"leowei08@gmail.com\" \n",
    "password = 'password'\n",
    "message = \"\"\"\\\n",
    "Subject: Predictions Today {today}\n",
    "\n",
    "\n",
    "{content}.\"\"\"\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
    "    server.login(sender_email, password)\n",
    "    server.sendmail(sender_email, receiver_email1, message.format(today=str(datetime.date.today()).replace('-',''), content=s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
